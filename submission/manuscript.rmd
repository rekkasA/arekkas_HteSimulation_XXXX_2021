---
title: "Models including an interaction of treatment with baseline risk were better able to predict absolute benefit in simulations"
abstract: |
 **Objective:** To compare different risk-based methods predicting individualized treatment effects in RCT simulations. **Study Design and Setting:** We simulated data using diverse assumptions for a baseline prognostic index of risk (PI) and the shape of its intereraction with treatment (none, linear or quadratic). In each sample we predicted absolute benefit using: models with the PI and a constant relative treatment effect; models including an interaction of treatment with the PI; stratification in quarters of the PI; nonlinear transformations of the PI (restricted cubic splines with 3, 4 and 5 knots); an adaptive approach using Akaike’s Information Criterion. We evaluated predictive performance using root mean squared error and measures of discrimination and calibration for benefit. Starting from a base case scenario (sample size 4,250, treatment odds ratio 0.8, AUC of the PI 0.75), we varied the sample size, the treatment effect strength, and the PI's discriminative ability. **Results:** Models including a PI by treatment interaction performed better under most simulation settings. Flexible models required larger sample sizes and higher AUC of the PI to outperform the linear interaction model. The adaptive approach performed similarly to the best-performing method in most scenarios. **Conclusion:** Usually, a model with a linear interaction of the PI with treatment is better able to predict absolute treatment benefit.
authors:
  - name: Alexandros Rekkas
    department: Department of Medical Informatics
    affiliation: Erasmus Medical Center
    location: Rotterdam, The Netherlands
  - name: Peter R. Rijnbeek
    department: Department of Medical Informatics
    affiliation: Erasmus Medical Center
    location: Rotterdam, The Netherlands
  - name: Ewout W. Steyerberg
    department: Department of Biomedical Data Sciences
    affiliation: Leiden University Medical Center
    location: Leiden, The Netherlands
  - name: David van Klaveren
    department: Department of Public Health
    affiliation: Erasmus Medical Center
    location: Rotterdam, The Netherlands
keywords:
  - treatment effect heterogeneity
  - absolute benefit
  - prediction models
output: 
  rticles::arxiv_article:
    keep_tex: true
  bookdown::word_document2:
    reference_docx: reference.docx
geometry: margin=1.0in
date: false
toc: false
font-size: 11pt
header-includes:
  - \renewcommand*\familydefault{\sfdefault}
  - \usepackage{setspace}
  - \usepackage{amsmath}
  - \doublespacing
  - \usepackage[left]{lineno}
  - \usepackage{amssymb}
  - \usepackage{bm}
  - \usepackage{booktabs}
  - \newcommand\given[1][]{\:#1\vert\:}
  - \date{}
editor_options: 
  chunk_output_type: console
bibliography: references.bib
csl: jce.csl
---


```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(SmoothHte)
library(rms)

d <- function(x, decimals = 2) {
  sprintf(paste0("%1.", decimals, "f"), x) 
}

knit_hooks$set(
  inline = function(x) {
    prettyNum(
      x,
      big.mark = ",",
      decimal.mark = ".",
      preserve.width = "individual"
    )
  }
)
```

\linenumbers
# Introduction
Predictive approaches for assessing heterogeneity of treatment effects (HTE) aim
at the development of models predicting either individualized effects or which
of two (or more) treatments is better for an individual [@Varadhan2013]. In
prior work, we divided such methods in three broader categories based on the
reference class used for defining patient similarity when making individualized
predictions or recommendations [@Rekkas2020]. Risk-modeling approaches use
prediction of baseline risk as the reference; treatment effect modeling
approaches also model treatment-covariate interactions, in addition to risk
factors; optimal treatment regime approaches focus on developing treatment
assignment rules and therefore rely heavily on modeling treatment effect
modifiers.

Risk-modeling approaches to predictive HTE analyses provide a viable option in
the absence of well-established treatment effect modifiers [@Kent2019;
@PathEnE]. In simulations, modeling of effect modifiers, i.e.
treatment-covariate interactions, often led to miscalibrated predictions of
benefit, while risk-based methods proved quite robust [@vanKlaveren2019]. Most
often, risk-modeling approaches are carried out in two steps: first a risk
prediction model is developed externally or internally on the entire RCT
population, “blinded” to treatment; then the RCT population is stratified using
this prediction model to evaluate risk-based treatment effect variation
[@Kent2010]. However, even though estimates at the risk subgroup level may be
accurate, these estimated do not apply to individual patients, especially for
patients with predicted risk at the boundaries of the risk intervals. Hence, the
risk-stratified approach is useful for exploring and presenting HTE, but is not
useful for supporting treatment decisions for individual patients.

To individualize treatment effects, the recent PATH statement suggested various
risk-based models including a prognostic index of baseline risk (PI) and
treatment assignment [cite PATH !!]. We aimed to summarize and compare different
risk-based models for predicting individualized treatment effects. We simulated
RCT settings to compare the performance of these models under different
assumptions of the relationship between baseline risk and treatment. We
illustrated the different models by a case study of predicting individualized
effects of tissue plasminogen activator (tPA) versus streptokinase treatment in
patients with an acute myocardial infarction (MI).

# Methods

## Simulation scenarios

In the simulated datasets based treatment was allocated at random using a 50:50
split. For each patient we simulated $8$ baseline covariates, where
$x_1,\dots,x_4\sim N(0, 1)$ and $x_5,\dots,x_8\sim B(1, 0.2)$. Outcomes
for patients in the control arm were generated from a logistic regression model
including all baseline covariates. Coefficient values were such, so that the
prediction model had an AUC of $0.75$ and an event rate of $20\%$ in the control
arm was achieved. Under the base case scenario, outcomes in the treatment arm
were created using the same logistic regression model, including a constant
treatment odds ratio (OR) of $0.8$. The generated samples of the base case
scenario had sample size of 4,250 ($85%$ power for the detection of an
unadjusted OR of $0.8$).

We evaluated the effect of sample size considering additional scenarios with
sample sizes of `r 1064` and `r 17000`. We also evaluated the effect of prediction
performance, adjusting the baseline covariate coefficients, so that AUC values
of $0.65$ and $0.80$ were achieved when validating in a simulated dataset of
500,000 patients.

We simulated binary outcomes in the control arm using true probabilities 
$P(y=1|X) = \text{expit}(PI)$, where 
$\text{expit}(x)= \frac{e^x}{1 + e^x}$. 
In the treatment arm outcomes where generated with probabilities
$\text{expit}(lp_1)$ with
$$ lp_1 = \gamma_2(PI-c)^2 + \gamma_1(PI-c) + \gamma_0,$$
where the coefficients $\gamma_0, \gamma_1$ and $\gamma_2$ along with the
centering constant $c$ were set for each simulation scenario. In this way we
were able to assess a wide variety of scenarios, ranging from true constant
relative treatment effects to moderate and strong linear and quadratic
deviations. We also considered scenarios with treatment-covariate interactions.
These scenarios include 4 weak interactions
($\text{OR}_{t_x=1} / \text{OR}_{t_x=0}=0.82$), 
4 strong interactions 
($\text{OR}_{t_x=1} / \text{OR}_{t_x=0}=0.61$), 
and 2 weak and 2 strong interactions. Combining all these different settings
resulted in a simulation study of $66$ scenarios. The exact settings for each
scenario are available in the supplementary material.

## Individualized risk-based benefit predictions

All methods assume that a risk prediction model is available and can be used to
assign individualized risk predictions. For the simulations we developed the
prediction models internally and blinded to treatment using logistic regression
including main effects for all baseline covariates and treatment. Risk
predictions on individuals were made setting treatment to $0$.

The *stratified HTE method* has been suggested as an alternative to
traditional subgroup analyses. Patients are stratified into equally-sized risk
strata---in this case based on risk quartiles. Absolute effects are estimated
using the differences in event rates between treatments within risk quarters. We
considered this approach as a reference, expecting it to perform worse than the
other candidates, as its objective is not individualized benefit prediction.

Another approach would be to assume *constant relative treatment effect* (OR) is
constant. In that case, absolute benefit is estimated from
$\hat{\tau}(\bm{x}) = \text{expit}(PI +\log(\text{OR}))$. This is the method
usually considered when performing risk-based assessment of treatment effect
heterogeneity in RCT data.

A different approach fits a logistic regression using treatment, the prognostic
index and their interaction. In this case absolute benefit is estimated from
$\hat{\tau}(\bm{x})=\text{expit}(\beta_0+\beta_{PI}PI) - \text{expit}(\beta_0+\beta_{t_x}+(\beta_{PI}+\beta_*)PI)$.
We will refer to this method as the *linear interaction* approach.

Finally, we used *restricted cubic splines* (RCS) to relax the linearity assumption on
the effect of the linear predictor [@Harrell1988]. We compared the results
for 3, 4 and 5 knots when fitting the splines to introduce increasing
flexibility to the methods considered.

## Evaluation metrics

For evaluating the prediction error of the considered methods we used root mean
squared error (RMSE), since both the true and the predicted benefits are known,
given that this is a simulation study. More specifically, we calculated RMSE
from
$$\text{RMSE}=\frac{1}{n}\sum_{i=1}^n\big(\tau(\bm{x}_i) - \hat{\tau}(\bm{x}_i)\big)^2$$

We also compared the discriminative ability of the methods under study. We
assessed discrimination using the c-for-benefit statistic described in
[@vanKlaveren2018]. Patients in each treatment arm are ranked based on their
predicted benefit and then are matched 1:1, dropping patients in the larger
treatment arm without a pair. We define *observed* pair-specific treatment
benefit as the difference of observed outcomes between the untreated and the
treated patient of each pair. Pair-specific *predicted* benefit is defined as
the average of predicted benefits within each pair. Then, c-for-benefit is
defined as the probability that from two randomly chosen matched patient pairs
with unequal observed benefit, the pair with greater observed benefit also has a
higher predicted benefit.

We evaluated calibration in a similar manner, using the integrated calibration
index (ICI) for benefit [@Austin2019]. After creating pairs based on predicted
benefit, observed benefits are regressed on the predicted benefits using a
locally weighted scatterplot smoother (loess). The ICI is the average absolute
difference between predicted and smooth observed benefit. Values closer to $0$
represent better calibration.


# Results

## Simulations


The model including a constant relative treatment effect had the lowest median
RMSE in scenarios with a true constant relative treatment effect (OR = 0.8, N =
`r 4250` and AUC = 0.75) or moderate relative deviations were considered (Figure
\ref{fig:rmsebase}; Panel A). However, when we considered strong linear and
quadratic deviations from a constant relative treatment effect the linear
interaction model performed best (Figure \ref{fig:rmsebase}; Panels B and C).
Only in the case of strong quadratic deviations models including RCS (3 knots)
performed equally well to the linear interaction method. Increasing the number
of knots in RCS resulted in higher error rates across all scenarios. The
adaptive approach performed very similarly to the best performing model in each
scenario.

```{r rmsebase, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated superpopulation of size 500,000. \\textit{Panel A} presents the results of the scenario with true constant relative treatment effect, with a true prediction AUC of 0.75 and sample size of 4250; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effects; \\textit{Panel C} presents the results for strong linear deviations from constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations from constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/rmse_base.png"))
```

When we increased the sample size (N = `r 17000`), the model including a
constant relative treatment effect had the lowest RMSE under the assumption of
true constant relative treatment effects (Figure \ref{fig:rmsesamplesize};
Panel A). Contrary to previous results with smaller sample sizes, when
introducing moderate and strong linear deviations the linear interaction model
performed best, outperforming the constant treatment effect model (Figure
\ref{fig:rmsesamplesize}; Panels B and C). However, the linear interaction
model was outperformed by the more flexible RCS models (3 knots) in the case of
strong quadratic deviations. Again, the increased flexibility of RCS smoothing
with higher number of knots resulted in overfitting and worse performance
(Figure \ref{fig:rmsesamplesize}; Panel D).

```{r rmsesamplesize, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated sample of size 500,000. \\textit{Panel A} presents the results under the base case scenario of true constant relative treatment effect, with a true prediction AUC of 0.75 and sample size of 17,000; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effects; \\textit{Panel C} presents the results for strong linear deviations from constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/rmse_sample_size.png"))
```

When we increased the true prediction AUC to 0.85, models including RCS
smoothing had the lowest RMSE in the presence of strong quadratic deviations
from the base case of true constant relative treatment effects (Figure
\ref{fig:rmseauc}; Panel D). However, with milder deviations, the linear
interaction model had the lowest RMSE with the RCS smoothing methods (3 knots)
being a close second (Figure \ref{fig:rmseauc}; Panels B and C). Increasing the
number of knots of RCS smoothing resulted in increased RMSE, which was less
pronounced in the case of strong quadratic deviations.

```{r rmseauc, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated sample of size 500,000. \\textit{Panel A} presents the results under the base case scenario of true constant relative treatment effect, with a true prediction AUC of 0.85 and sample size of 4,250; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effects, while holding true prediction AUC and sample size constant; \\textit{Panel C} presents the results for strong linear deviations from constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations from constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/rmse_auc.png"))
```

The constant effects model, the linear interaction model and models with RCS
smoothing (3 knots) had the highest median c-for-benefit in the base case
scenario and the scenarios where linear and quadratic deviations were
considered. The constant treatment effect model and the linear interaction model
tended to present much lower variability compared to all other approaches
(Figure \ref{fig:discrimination}). We also observed an increasing trend of
discrimination for benefit variability and decreasing median values with
increasing number of restricted cubic spline knots in all scenarios.


```{r discrimination, echo=FALSE, fig.cap="Discrimination for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. \\textit{Panel A} presents the results under the base case scenario of true constant relative treatment effect, with a true prediction AUC of 0.75 and sample size of 4250; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effects; \\textit{Panel C} presents the results for strong linear deviations from constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations from constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/discrimination_base.png"))
```

When focusing on calibration, the linear interaction model had the lowest median
ICI for benefit in the majority of scenarios except for the scenarios where no
or moderate linear deviations from the base case were considered. In that case
constant treatment effect models demonstrated the best performance, very
comparable to the linear interaction model's performance, nonetheless (Figure
\ref{fig:calibration}). However, under strong linear or
quadratic deviations, the constant treatment effect model was very poorly
calibrated (Figure \ref{fig:calibration}; Panels C and D).

```{r calibration, echo=FALSE, fig.cap="Calibration for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. \\textit{Panel A} presents the results under the base case scenario of true constant relative treatment effect, with a true prediction AUC of 0.75 and sample size of 4250; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effectst; \\textit{Panel C} presents the results for strong linear deviations from of constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations from constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/calibration_base.png"))
```

## Case study
```{r, echo=FALSE, warning=FALSE, message=FALSE}
load(here::here("data/raw/gusto.rda"))
gusto <- gusto %>%
  tibble() %>%
  filter(!is.na(tpa))

treatmentArms <- gusto %>%
  group_by(tpa) %>%
  summarise(n = n())
```

We demonstrate the different methods for individualizing treatment benefits
using data from `r nrow(gusto)` patients with an acute myocardial infarction
(MI) included in the GUSTO-I trial.
`r treatmentArms %>% filter(tpa == 1) %>% select(n)` patients were randomized to
tissue plasminogen activator (tPA) treatment and
`r treatmentArms %>% filter(tpa == 0) %>% select(n)` were randomized to
streptokinase. The outcome of interest was 30-day mortality, recorded for all
patients.

In line with previous analyses [@Califf1997; @Steyerberg2000], we fitted a logistic regression
model with 6 baseline covariates, i.e. age, Killip class, systolic blood
pressure, heart rate, an indicator of previous MI, and the location of MI, to
predict 30-day mortality risk. A constant effect of treatment was included in
the model. When deriving risk predictions for individuals we set the treatment
indicator to 0. More information on model development can be found in the
supplement.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
gusto <- gusto %>%
  tibble() %>%
  rename(
    "outcome" = "day30",
    "treatment" = "tpa"
  )

prediction <- lrm(
  outcome ~ treatment + age + Killip + pmin(sysbp, 120) + lsp(pulse, 50) + pmi + miloc,
  data = gusto,
  maxit = 99
)

riskLinearPredictor <- predict(
  prediction,
  newdata = gusto %>% mutate(treatment = 0) %>% data.frame()
)

gusto <- gusto %>%
  mutate(
    riskLinearPredictor = riskLinearPredictor
  )

constantModel <- fitModelBasedHte(
  data     = gusto, 
  settings = createModelBasedSettings(type = "treatment")
)

tmp <- gusto %>%
  mutate(
    predictedBenefit = predictBenefitModelBasedHte(
      p             = plogis(.$riskLinearPredictor), 
      modelBasedFit = constantModel
    )
  )

constantC   <- calculateCForBenefit(tmp)
constantIci <- calculateCalibrationForBenefit(tmp)

stratified <- fitStratifiedHte(
  data     = gusto,
  settings = createStratifiedSettings()
)

linearModel <- fitModelBasedHte(
  data     = gusto,
  settings = createModelBasedSettings()
)

tmp <- gusto %>%
  mutate(
    predictedBenefit = predictBenefitModelBasedHte(
      p             = plogis(.$riskLinearPredictor), 
      modelBasedFit = linearModel
    )
  )

linearC   <- calculateCForBenefit(tmp)
linearIci <- calculateCalibrationForBenefit(tmp)

rcs3Model <- fitRcsHte(
  data     = gusto,
  settings = createRcsSettings()
)

tmp <- gusto %>%
  mutate(
    predictedBenefit = predictSmoothBenefit(
      p          = plogis(riskLinearPredictor), 
      smoothFit  = rcs3Model
    )
  )

rcs3C   <- calculateCForBenefit(tmp)
rcs3Ici <- calculateCalibrationForBenefit(tmp)


rcs4Model <- fitRcsHte(
  data     = gusto,
  settings = createRcsSettings(nKnots = 4)
)

tmp <- gusto %>%
  mutate(
    predictedBenefit = predictSmoothBenefit(
      p          = plogis(riskLinearPredictor), 
      smoothFit  = rcs4Model
    )
  )

rcs4C   <- calculateCForBenefit(tmp)
rcs4Ici <- calculateCalibrationForBenefit(tmp)

rcs5Model <- fitRcsHte(
  data     = gusto,
  settings = createRcsSettings(nKnots = 5)
)

tmp <- gusto %>%
  mutate(
    predictedBenefit = predictSmoothBenefit(
      p          = plogis(.$riskLinearPredictor), 
      smoothFit  = rcs5Model
    )
  )

rcs5C   <- calculateCForBenefit(tmp)
rcs5Ici <- calculateCalibrationForBenefit(tmp)

gustoPerformance <- tibble(
  discrimination = c(
    constantC, linearC, rcs3C,
    rcs4C, rcs5C
  ),
  calibration = c(
    constantIci$ici, linearIci$ici, rcs3Ici$ici,
    rcs4Ici$ici, rcs5Ici$ici
  ),
  method = c(
    "constant treatment effect",
    "linear interaction",
    "RCS smoothing with 3 knots",
    "RCS smoothing with 4 knots",
    "RCS smoothing with 5 knots"
  )
)

cBenefit <- gustoPerformance %>% arrange(discrimination)

```

We used the risk linear predictor to fit the the proposed methods under study
for individualizing absolute benefit predictions. All methods had quite
comparable results, in the sense that we predicted increasing benefits for
patients with higher baseline risk predictions. In terms of c-for-benefit 
(validated internally) all models had quite comparable performance ranging from
0.519 (RCS smoothing with 3 knots) to 0.542 (RCS smoothing with 4 knots).
Similar conclusions could be drawn in terms of ICI-for-benefit which ranged
from 0.0039 (linear interaction approach) to 0.0053 (RCS smoothing with 4
knots).

The adaptive approach picked the
model with RCS smoothing with 4 knots, which had quite comparable performance to
the smooth fit with 5 knots. However, for lower baseline risk these 2 models
predicted implausible benefits and maybe should be avoided when applying such
models in practice. The linear interaction model and the model with RCS
smoothing (3 knots) made very similar predictions and also followed quite
closely the evolution of the stratified estimates. In this case, we observed
that even using a simple model with a constant relative treatment effect can
result in very similar benefit predictions as other more complex approaches.

```{r gusto, echo=FALSE, fig.cap="Individualized absolute benefit predictions based on baseline risk when using a constantn treatment effect approach, a linear interaction approach and RCS smoothing using 3,4 and 5 knots. Risk stratified estimates of absolute benefit are presented within quartiles of baseline risk as reference.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/gusto.png"))
```

# Discussion

The linear interaction model proved to be superior to alternative approaches
when predicting risk-based treatment benefit under a wide range of scenarios. It
generally had lower mean squared error, lower e-for-benefit and higher
c-for-benefit with lower variability across simulation replications. Models
including restricted cubic splines with 3 knots only outperformed the linear
interaction model in the presence of strong quadratic deviations from a constant
relative treatment effect.

Including restricted cubic splines with 4 or 5 knots proved to be too flexible,
as indicated by higher RMSE, increased variability of discrimination for benefit
and worse calibration of benefit predictions. Even with larger sample sizes and
strong quadratic deviations from the base case scenario of constant relative
treatment effects, these more flexible restricted cubic splines did not
outperform the simpler RCS with 3 knots. These more flexible approaches may only
be helpful if we expect more extreme patterns of heterogeneous treatment
effects.

The constant treatment effect model, despite having adequate performance in the
presence of weak treatment effect heterogeneity on the relative scale, quickly
broke down with stronger deviations from constant relative treatment effects. In
these cases, the stratified approach generally had lower error rates compared to
the constant treatment effect model. Stepwise treatment benefit estimates are
very useful for demonstrating treatment effect heterogeneity--because
estimating treatment effect requires groups of patients rather than individual
patients--but are not helpful for making individualized absolute benefit
predictions.

Increasing the discriminative ability of the risk model – by increasing the
predictor coefficients of the true risk model – reduced RMSE for all methods.
This increase in discriminative ability translates in higher variability of
predicted risks, which, in turn, allows the considered methods to better capture
absolute treatment benefits. As a consequence, the increase in discriminative
ability of the risk model also led to higher values of c-for-benefit. Even
though risk model performance is very important for the ability of risk-based
methods to predict treatment benefit, prediction model development was outside
the scope of this work and has already been studied extensively
[@vanKlaveren2019; @Burke2014; @Abadie2018].

Risk-based approaches to predictive HTE estimate treatment benefit as a function
of baseline risk. A limitation of our study is that we assumed treatment benefit
to be a function of baseline risk in the majority of the simulation scenarios.
Nevertheless, our main conclusions did not change when we generated individual
treatment-covariate interactions (supplementary table/figure x). Future
simulation studies could explore the effect of more extensive deviations from
risk-based treatment effects.

Recent years have seen an increased interest in predictive HTE approaches
focusing on individualized benefit predictions. In our simulations we only
focused on risk-based methods, using baseline risk as a reference in a two-stage
approach to individualizing benefit predictions. However, there is a plethora of
different methods, ranging from treatment effect modeling to tree-based
approaches available in more recent literature [@Athey2019; @Lu2018;
@Wager2018]. Simulations are also needed to assess relative performance and
define the settings where these break down or outperform each other.

In conclusion, when comparing different risk-based approaches to predict
individualizing benefit a models including a linear treatment interaction with
the prognostic performed best in a wide range of scenarios. More flexible models
with restricted cubic splines required larger sample sizes and higher AUC of the
PI to outperform the linear model. An adaptive approach, selecting the model
with optimal AIC, had comparable performance to the best performing approach in
most of the scenarios.


\newpage
# References
\nolinenumbers
\setlength{\parindent}{-0.25in}
\setlength{\leftskip}{0.25in}
\noindent
<div id="refs"></div>
\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}
\noindent
